{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Segunda Etapa: Preparação para Modelagem e Treinamento dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chegamos na segunda etapa do projeto. Trouxemos o dataframe final da última etapa e vamos começar o trabalho. Os próximos passos são:\n",
    "\n",
    "Aplicar escalonamento nas variáveis numéricas\n",
    "Utilizar One-Hot Encoding para variáveis categóricas\n",
    "Verificar o desbalanceamento na variável target\n",
    "Dividir os Dados em Conjuntos\n",
    "Depois, minha ideia é treinar os seguintes modelos:\n",
    "\n",
    "Regrssao logistica,\n",
    "Randon_forest,\n",
    "Arvore de decisão,\n",
    "cat_boost,\n",
    "xg_boost\n",
    "Nessa etapa, eu pretendo aplicar a validação cruzada e o gridsearch para afiar o treinmento e encontrar os melhores parâmetros para cada modelo. Assim, buscamos atingir o melhor AUC-ROC possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframe_filtrado_projeto_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin_date</th>\n",
       "      <th>is_client</th>\n",
       "      <th>time_of_contract_years</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>online_security</th>\n",
       "      <th>online_backup</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>multiple_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>One year</td>\n",
       "      <td>False</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>True</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "      <td>One year</td>\n",
       "      <td>False</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>True</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>True</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>99.65</td>\n",
       "      <td>820.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   begin_date  is_client  time_of_contract_years            type  \\\n",
       "0  2017-04-01          1                    2.84        One year   \n",
       "1  2019-10-01          0                    0.17  Month-to-month   \n",
       "2  2016-05-01          1                    3.76        One year   \n",
       "3  2019-09-01          0                    0.17  Month-to-month   \n",
       "4  2019-03-01          0                    0.67  Month-to-month   \n",
       "\n",
       "   paperless_billing             payment_method  monthly_charges  \\\n",
       "0              False               Mailed check            56.95   \n",
       "1               True               Mailed check            53.85   \n",
       "2              False  Bank transfer (automatic)            42.30   \n",
       "3               True           Electronic check            70.70   \n",
       "4               True           Electronic check            99.65   \n",
       "\n",
       "   total_charges  gender  senior_citizen  partner  dependents  \\\n",
       "0        1889.50       1               0    False       False   \n",
       "1         108.15       1               0    False       False   \n",
       "2        1840.75       1               0    False       False   \n",
       "3         151.65       0               0    False       False   \n",
       "4         820.50       0               0    False       False   \n",
       "\n",
       "   internet_service  online_security  online_backup  device_protection  \\\n",
       "0                 0                1              0                  1   \n",
       "1                 0                1              1                  0   \n",
       "2                 0                1              0                  1   \n",
       "3                 1                0              0                  0   \n",
       "4                 1                0              0                  1   \n",
       "\n",
       "   tech_support  streaming_tv  streaming_movies  multiple_lines  \n",
       "0             0             0                 0               0  \n",
       "1             0             0                 0               0  \n",
       "2             1             0                 0               0  \n",
       "3             0             0                 0               0  \n",
       "4             0             1                 1               1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Começando a Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6784, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin_date</th>\n",
       "      <th>is_client</th>\n",
       "      <th>time_of_contract_years</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>...</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>type_One year</th>\n",
       "      <th>type_Two year</th>\n",
       "      <th>payment_method_Credit card (automatic)</th>\n",
       "      <th>payment_method_Electronic check</th>\n",
       "      <th>payment_method_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>False</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "      <td>False</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>True</td>\n",
       "      <td>99.65</td>\n",
       "      <td>820.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   begin_date  is_client  time_of_contract_years  paperless_billing  \\\n",
       "0  2017-04-01          1                    2.84              False   \n",
       "1  2019-10-01          0                    0.17               True   \n",
       "2  2016-05-01          1                    3.76              False   \n",
       "3  2019-09-01          0                    0.17               True   \n",
       "4  2019-03-01          0                    0.67               True   \n",
       "\n",
       "   monthly_charges  total_charges  gender  senior_citizen  partner  \\\n",
       "0            56.95        1889.50       1               0    False   \n",
       "1            53.85         108.15       1               0    False   \n",
       "2            42.30        1840.75       1               0    False   \n",
       "3            70.70         151.65       0               0    False   \n",
       "4            99.65         820.50       0               0    False   \n",
       "\n",
       "   dependents  ...  device_protection  tech_support  streaming_tv  \\\n",
       "0       False  ...                  1             0             0   \n",
       "1       False  ...                  0             0             0   \n",
       "2       False  ...                  1             1             0   \n",
       "3       False  ...                  0             0             0   \n",
       "4       False  ...                  1             0             1   \n",
       "\n",
       "   streaming_movies  multiple_lines  type_One year  type_Two year  \\\n",
       "0                 0               0              1              0   \n",
       "1                 0               0              0              0   \n",
       "2                 0               0              1              0   \n",
       "3                 0               0              0              0   \n",
       "4                 1               1              0              0   \n",
       "\n",
       "   payment_method_Credit card (automatic)  payment_method_Electronic check  \\\n",
       "0                                       0                                0   \n",
       "1                                       0                                0   \n",
       "2                                       0                                0   \n",
       "3                                       0                                1   \n",
       "4                                       0                                1   \n",
       "\n",
       "   payment_method_Mailed check  \n",
       "0                            1  \n",
       "1                            1  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['type', 'payment_method'], drop_first=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos o One-Hot-Encoding para as variáveis categóricas restantes (duas). Agora, vamos separar features e target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['is_client']\n",
    "features = df.drop(columns='is_client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: (5088, 21)\n",
      "Tamanho do conjunto de teste: (1696, 21)\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features,\n",
    "    target,\n",
    "    test_size=0.25,\n",
    "    stratify=target,\n",
    "    random_state=12345\n",
    ")\n",
    "\n",
    "features_train = features_train.drop(columns=['begin_date'])\n",
    "features_test = features_test.drop(columns=['begin_date'])\n",
    "\n",
    "print(\"Tamanho do conjunto de treino:\", features_train.shape)\n",
    "print(\"Tamanho do conjunto de teste:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando o Escalonamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = features.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "features_train_unscaled = features_train.copy()\n",
    "features_test_unscaled = features_test.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_train_scaled = features_train.copy()\n",
    "features_test_scaled = features_test.copy()\n",
    "\n",
    "features_train_scaled[numeric_cols] = scaler.fit_transform(features_train[numeric_cols])\n",
    "features_test_scaled[numeric_cols] = scaler.transform(features_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superamostragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_majority = features_train[target_train == 1]\n",
    "features_minority = features_train[target_train == 0]\n",
    "target_majority = target_train[target_train == 1]\n",
    "target_minority = target_train[target_train == 0]\n",
    "\n",
    "repeat_factor = int(len(target_majority) / len(target_minority))\n",
    "features_minority_upsampled = pd.concat([features_minority] * repeat_factor)\n",
    "target_minority_upsampled = pd.concat([target_minority] * repeat_factor)\n",
    "\n",
    "features_train_super = pd.concat([features_majority, features_minority_upsampled])\n",
    "target_train_super = pd.concat([target_majority, target_minority_upsampled])\n",
    "features_train_super, target_train_super = shuffle(features_train_super, target_train_super, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_train_super_scaled = scaler.fit_transform(features_train_super)\n",
    "target_train_super_scaled = target_train_super.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de feita a divisão, temos o escalonamento das variáveis categóricas e uma superamostragem para tratar o desbalanceamento. Criei variáveis preenchidas com todas as versões possíveis dos conjuntos de dados. Assim, temos versões se nenhuma transformação, ou então apenas com escalonamento, apenas com super amostragem e com mabas as transformações juntas. Assim, poderemos fazer diversos testes para procurar a melhor AUC ROC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando os Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, vamos começar o treinamento de modelos. Minha abordagem é a seguinte: Vamos testar cada modelo com cada uma das variações dos tipos de dados, usando os parâmetros padrões de cada modelo. Pegaremos o melhor resultado e aplicaremos a validação cruzada e o gridsearch pra otimizar o resultado. Então, passaremos para o próximo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        AUC-ROC  Accuracy\n",
      "OHE apenas               0.7052    0.7571\n",
      "Escalonamento apenas     0.7054    0.7565\n",
      "Superamostragem apenas   0.7155    0.7759\n",
      "Super + Escalonamento    0.6896    0.7111\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "datasets = {\n",
    "    'OHE apenas': (features_train, features_test, target_train, target_test),\n",
    "    'Escalonamento apenas': (features_train_scaled, features_test_scaled, target_train, target_test),\n",
    "    'Superamostragem apenas': (features_train_super, features_test, target_train_super, target_test),\n",
    "    'Super + Escalonamento': (features_train_super_scaled, features_test_scaled, target_train_super_scaled, target_test),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    y_pred = tree_model.predict(X_test)\n",
    "    y_proba = tree_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {'AUC-ROC': round(auc, 4), 'Accuracy': round(acc, 4)}\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses resultados me parecem promissores. Faz sentido que o melhor resultado aqui tenha sido o sem escalonamento, porque a Árvore de Decisão vai bem sem essa alteração. Vamos aplicar uma validação cruzada e um gridSeach para otimizar nossa árvore ainda mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validação Cruzada e GridSearch na Árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Melhores parâmetros: {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Melhor AUC-ROC (validação cruzada): 0.8909\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tree,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(features_train_super, target_train_super)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "print(\"Melhor AUC-ROC (validação cruzada):\", round(grid_search.best_score_, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses resultados já são muito bons, mas precisamos que eles sejam mantidos, denytro do possível, no conjunto de teste. Faremos esse teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC (teste): 0.7516\n",
      "Acurácia (teste): 0.7695\n"
     ]
    }
   ],
   "source": [
    "best_tree = DecisionTreeClassifier(\n",
    "    random_state=12345,\n",
    "    criterion='entropy',\n",
    "    max_depth=15,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1\n",
    ")\n",
    "\n",
    "best_tree.fit(features_train_super, target_train_super)\n",
    "\n",
    "y_pred_test = best_tree.predict(features_test)\n",
    "y_proba_test = best_tree.predict_proba(features_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "auc_test = roc_auc_score(target_test, y_proba_test)\n",
    "acc_test = accuracy_score(target_test, y_pred_test)\n",
    "\n",
    "print(\"AUC-ROC (teste):\", round(auc_test, 4))\n",
    "print(\"Acurácia (teste):\", round(acc_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, tivemos uma queda dentro do esperado. Temos um leve overfitting, mas isso é normal. O modelo já atingiu um AUC ROC que nos foi pedido. Vamos seguir com os outros treinamentos e ver se conseguimos resultados ainda melhores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        AUC-ROC  Accuracy\n",
      "OHE apenas               0.8624    0.8160\n",
      "Escalonamento apenas     0.8622    0.8166\n",
      "Superamostragem apenas   0.8628    0.8054\n",
      "Super + Escalonamento    0.8421    0.7818\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "datasets = {\n",
    "    'OHE apenas': (features_train, features_test, target_train, target_test),\n",
    "    'Escalonamento apenas': (features_train_scaled, features_test_scaled, target_train, target_test),\n",
    "    'Superamostragem apenas': (features_train_super, features_test, target_train_super, target_test),\n",
    "    'Super + Escalonamento': (features_train_super_scaled, features_test_scaled, target_train_super_scaled, target_test),\n",
    "}\n",
    "\n",
    "results_rf = {}\n",
    "\n",
    "for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results_rf[name] = {'AUC-ROC': round(auc, 4), 'Accuracy': round(acc, 4)}\n",
    "\n",
    "results_rf_df = pd.DataFrame(results_rf).T\n",
    "print(results_rf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados muito bons, ainda mais considerando que usamos os parâmetros padrões da Floresta e não aplicamos validação ainda. Vamos para essa etapa!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validação Cruzada e GridSearch na Floresta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Melhores parâmetros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Melhor AUC-ROC (validação cruzada): 0.964\n"
     ]
    }
   ],
   "source": [
    "X_train = features_train_super\n",
    "y_train = target_train_super\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_search_rf.best_params_)\n",
    "print(\"Melhor AUC-ROC (validação cruzada):\", round(grid_search_rf.best_score_, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um valor muito alto! Vamos verificar quanto ele nos retorna no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC (teste): 0.8615\n",
      "Acurácia (teste): 0.8137\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=200,\n",
    "    random_state=12345\n",
    ")\n",
    "\n",
    "best_rf.fit(features_train_super, target_train_super)\n",
    "\n",
    "y_test_pred = best_rf.predict(features_test)\n",
    "y_test_proba = best_rf.predict_proba(features_test)[:, 1]\n",
    "\n",
    "auc_roc_test = roc_auc_score(target_test, y_test_proba)\n",
    "acc_test = accuracy_score(target_test, y_test_pred)\n",
    "\n",
    "print(\"AUC-ROC (teste):\", round(auc_roc_test, 4))\n",
    "print(\"Acurácia (teste):\", round(acc_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um resultado muito bom dentro dos parâmetros esperados pelo projeto. Uma nova queda de cerca de 0.1, mas ainda me parece dentro dos limites aceitáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        AUC-ROC  Accuracy\n",
      "OHE apenas               0.8508    0.8042\n",
      "Escalonamento apenas     0.8528    0.8072\n",
      "Superamostragem apenas   0.8502    0.7860\n",
      "Super + Escalonamento    0.8495    0.7795\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "datasets = {\n",
    "    'OHE apenas': (features_train, features_test, target_train, target_test),\n",
    "    'Escalonamento apenas': (features_train_scaled, features_test_scaled, target_train, target_test),\n",
    "    'Superamostragem apenas': (features_train_super, features_test, target_train_super, target_test),\n",
    "    'Super + Escalonamento': (features_train_super_scaled, features_test_scaled, target_train_super_scaled, target_test),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    log_model.fit(X_train, y_train)\n",
    "    y_pred = log_model.predict(X_test)\n",
    "    y_proba = log_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {'AUC-ROC': round(auc, 4), 'Accuracy': round(acc, 4)}\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bons resultados mais uma vez. Vamos passar o próximo passo no conjunto que leva apenas o escalonamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearch e validação na Floresta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'C': 100, 'penalty': 'l2'}\n",
      "Melhor AUC-ROC (validação cruzada): 0.8566\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(features_train_scaled, target_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "print(\"Melhor AUC-ROC (validação cruzada):\", round(grid_search.best_score_, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Era esperado, mas esses resultados indicam que, muito provavelmente, não usaremos a regressão aqui. Vamos verificar como ela fica no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC (teste): 0.8529\n",
      "Acurácia (teste): 0.8066\n"
     ]
    }
   ],
   "source": [
    "best_log_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_test = best_log_model.predict(features_test_scaled)\n",
    "y_proba_test = best_log_model.predict_proba(features_test_scaled)[:, 1]\n",
    "\n",
    "auc_test = roc_auc_score(target_test, y_proba_test)\n",
    "acc_test = accuracy_score(target_test, y_pred_test)\n",
    "\n",
    "print(\"AUC-ROC (teste):\", round(auc_test, 4))\n",
    "print(\"Acurácia (teste):\", round(acc_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É interessante que a regressão manteve o resultado praticamente igual. Ela foi a melhor na generalização dos dados. Por pouco ela não acaba sendo a escolhida até aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        AUC-ROC  Accuracy\n",
      "OHE apenas               0.8859    0.8343\n",
      "Escalonamento apenas     0.8859    0.8343\n",
      "Superamostragem apenas   0.8845    0.8149\n",
      "Super + Escalonamento    0.8525    0.7718\n"
     ]
    }
   ],
   "source": [
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_state=12345,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "datasets = {\n",
    "    'OHE apenas': (features_train, features_test, target_train, target_test),\n",
    "    'Escalonamento apenas': (features_train_scaled, features_test_scaled, target_train, target_test),\n",
    "    'Superamostragem apenas': (features_train_super, features_test, target_train_super, target_test),\n",
    "    'Super + Escalonamento': (features_train_super_scaled, features_test_scaled, target_train_super_scaled, target_test),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    catboost_model.fit(X_train, y_train)\n",
    "    y_pred = catboost_model.predict(X_test)\n",
    "    y_proba = catboost_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {'AUC-ROC': round(auc, 4), 'Accuracy': round(acc, 4)}\n",
    "\n",
    "catboost_results_df = pd.DataFrame(results).T\n",
    "print(catboost_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados muito promissores. Vamos ver o impacto dos parâmetros e da validação cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearch e validação para o Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'depth': 4, 'iterations': 300, 'learning_rate': 0.1}\n",
      "Melhor AUC-ROC (validação cruzada): 0.8916\n"
     ]
    }
   ],
   "source": [
    "catboost_model = CatBoostClassifier(verbose=0, random_state=12345)\n",
    "\n",
    "catboost_params = {\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.03, 0.1],\n",
    "    'iterations': [200, 300]\n",
    "}\n",
    "\n",
    "grid_catboost = GridSearchCV(\n",
    "    estimator=catboost_model,\n",
    "    param_grid=catboost_params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_catboost.fit(features_train_scaled, target_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_catboost.best_params_)\n",
    "print(\"Melhor AUC-ROC (validação cruzada):\", round(grid_catboost.best_score_, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também não teve uma grande melhora, mas se esse modelo mantiver os resultyados como a regressão manteve, será o melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC (teste): 0.8924\n",
      "Acurácia (teste): 0.8426\n"
     ]
    }
   ],
   "source": [
    "best_catboost = CatBoostClassifier(\n",
    "    depth=4,\n",
    "    iterations=300,\n",
    "    learning_rate=0.1,\n",
    "    random_state=12345,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "best_catboost.fit(features_train_scaled, target_train)\n",
    "\n",
    "catboost_preds = best_catboost.predict(features_test_scaled)\n",
    "catboost_proba = best_catboost.predict_proba(features_test_scaled)[:, 1]\n",
    "\n",
    "catboost_auc = roc_auc_score(target_test, catboost_proba)\n",
    "catboost_acc = accuracy_score(target_test, catboost_preds)\n",
    "\n",
    "print('AUC-ROC (teste):', round(catboost_auc, 4))\n",
    "print('Acurácia (teste):', round(catboost_acc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tivemos até uma leve melhora! Ainda nos falta um modelo, mas nossa AUC ROC já superou todos os parâmetros esperados do projeto! Vamos treinar o XGBoost e ver o que conseguimos! Até aqui, a Catboost é a vencedora!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        AUC-ROC  Accuracy\n",
      "OHE apenas               0.8809    0.8325\n",
      "Escalonamento apenas     0.8808    0.8320\n",
      "Superamostragem apenas   0.8799    0.8190\n",
      "Super + Escalonamento    0.8225    0.7376\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=12345)\n",
    "\n",
    "datasets = {\n",
    "    'OHE apenas': (features_train, features_test, target_train, target_test),\n",
    "    'Escalonamento apenas': (features_train_scaled, features_test_scaled, target_train, target_test),\n",
    "    'Superamostragem apenas': (features_train_super, features_test, target_train_super, target_test),\n",
    "    'Super + Escalonamento': (features_train_super_scaled, features_test_scaled, target_train_super_scaled, target_test),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {'AUC-ROC': round(auc, 4), 'Accuracy': round(acc, 4)}\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez, bons valores. Vamos usar os dados com OHE apenas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch e Validação para o XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "Melhor AUC-ROC (validação cruzada): 0.8893\n"
     ]
    }
   ],
   "source": [
    "\"\"\"xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=12345\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6],\n",
    "    'learning_rate': [0.03, 0.1]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=xgb_params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_xgb.fit(features_train, target_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_xgb.best_params_)\n",
    "print(\"Melhor AUC-ROC (validação cruzada):\", round(grid_xgb.best_score_, 4))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Melhores parâmetros: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\\nMelhor AUC-ROC (validação cruzada): 0.8893\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Melhores parâmetros: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
    "Melhor AUC-ROC (validação cruzada): 0.8893\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estou deixando o código e os resultados comentados, porque essa célula precisou de algo entre 1 e 2 horas pra rodar. O resultado ficou um pouco abaixo do Catboost. Vamos ver como ele se sai no conjunto de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC (teste): 0.8893\n",
      "Acurácia (teste): 0.839\n"
     ]
    }
   ],
   "source": [
    "best_xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    n_estimators=100,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=12345\n",
    ")\n",
    "\n",
    "best_xgb.fit(features_train, target_train)\n",
    "\n",
    "xgb_preds = best_xgb.predict(features_test)\n",
    "xgb_proba = best_xgb.predict_proba(features_test)[:, 1]\n",
    "\n",
    "xgb_auc = roc_auc_score(target_test, xgb_proba)\n",
    "xgb_acc = accuracy_score(target_test, xgb_preds)\n",
    "\n",
    "print('AUC-ROC (teste):', round(xgb_auc, 4))\n",
    "print('Acurácia (teste):', round(xgb_acc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empate técnico com o Catboost, mas, consideando a demora muito maior para treinar e o fato de que esse modelo ainda ficou um pouco atrás, não há muitoa dúvida no qual escolher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sem grandes segredos, os dois modelos baseados em boost tiveram os melhores desempenhos finais, com o CatBooost sendo o melhor deles. De forma geral, todos os modelos tiveram desempenho muito bom e similar, com exceção da árvore de decisão, que ficou um pouco abaixo. Com isso, concluímos a segunda etapa do Projeto! "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 278,
    "start_time": "2025-03-25T13:09:44.079Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-25T13:09:45.964Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-25T13:09:50.295Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-25T13:21:17.621Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-25T13:21:18.283Z"
   },
   {
    "duration": 713,
    "start_time": "2025-03-25T13:51:20.857Z"
   },
   {
    "duration": 133,
    "start_time": "2025-03-25T13:53:25.131Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-25T13:53:28.937Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-25T13:53:43.218Z"
   },
   {
    "duration": 24,
    "start_time": "2025-03-25T13:57:35.141Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-25T14:18:27.937Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-25T14:18:28.348Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-25T14:18:28.894Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-25T14:18:32.208Z"
   },
   {
    "duration": 25,
    "start_time": "2025-03-25T14:22:29.432Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-25T14:29:47.768Z"
   },
   {
    "duration": 9,
    "start_time": "2025-03-25T14:37:44.850Z"
   },
   {
    "duration": 24,
    "start_time": "2025-03-25T14:43:43.663Z"
   },
   {
    "duration": 19,
    "start_time": "2025-03-25T15:14:39.672Z"
   },
   {
    "duration": 19,
    "start_time": "2025-03-25T15:15:16.441Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-25T15:16:05.294Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-25T15:16:23.063Z"
   },
   {
    "duration": 89,
    "start_time": "2025-03-25T15:16:23.068Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-25T15:16:23.159Z"
   },
   {
    "duration": 20,
    "start_time": "2025-03-25T15:16:23.172Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-25T15:16:23.194Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-25T15:16:23.200Z"
   },
   {
    "duration": 26,
    "start_time": "2025-03-25T15:16:23.208Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-25T15:16:23.235Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-25T15:16:23.250Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-25T15:20:05.226Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-25T15:20:10.076Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-25T15:20:10.085Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-25T15:20:10.102Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-25T15:20:10.118Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-25T15:20:10.142Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-25T15:20:10.148Z"
   },
   {
    "duration": 28,
    "start_time": "2025-03-25T15:20:10.156Z"
   },
   {
    "duration": 39,
    "start_time": "2025-03-25T15:20:10.186Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-25T15:20:10.227Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-25T15:20:27.226Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-25T15:20:28.056Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-25T15:20:28.678Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-25T15:20:31.221Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-25T15:20:35.432Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-25T15:20:36.171Z"
   },
   {
    "duration": 25,
    "start_time": "2025-03-25T15:20:39.328Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-25T15:20:41.884Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-25T15:26:08.404Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-25T15:26:17.183Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-25T15:26:29.372Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-25T15:26:34.917Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-25T15:26:34.926Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-25T15:26:34.945Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-25T15:26:34.962Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-25T15:26:34.987Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-25T15:26:34.996Z"
   },
   {
    "duration": 26,
    "start_time": "2025-03-25T15:26:35.031Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-25T15:26:35.059Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-25T15:26:35.103Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-25T15:30:48.368Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-25T15:30:52.949Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-25T15:30:52.955Z"
   },
   {
    "duration": 24,
    "start_time": "2025-03-25T15:30:52.971Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-25T15:30:52.999Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-25T15:30:53.021Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-25T15:30:53.027Z"
   },
   {
    "duration": 23,
    "start_time": "2025-03-25T15:30:53.037Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-25T15:30:53.062Z"
   },
   {
    "duration": 181,
    "start_time": "2025-03-25T15:30:53.099Z"
   },
   {
    "duration": 11189,
    "start_time": "2025-03-25T15:45:17.651Z"
   },
   {
    "duration": 44,
    "start_time": "2025-03-25T15:51:31.379Z"
   },
   {
    "duration": 1892,
    "start_time": "2025-03-25T16:33:26.796Z"
   },
   {
    "duration": 165057,
    "start_time": "2025-03-25T16:55:46.280Z"
   },
   {
    "duration": 1026,
    "start_time": "2025-03-25T17:01:34.747Z"
   },
   {
    "duration": 539,
    "start_time": "2025-03-25T17:07:53.308Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-25T17:09:14.820Z"
   },
   {
    "duration": 4982,
    "start_time": "2025-03-25T17:10:28.275Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-25T17:12:18.592Z"
   },
   {
    "duration": 1335,
    "start_time": "2025-03-25T17:18:49.423Z"
   },
   {
    "duration": 47142,
    "start_time": "2025-03-25T17:23:19.955Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-25T17:25:40.395Z"
   },
   {
    "duration": 541,
    "start_time": "2025-03-25T17:27:14.800Z"
   },
   {
    "duration": 345192,
    "start_time": "2025-03-25T17:41:38.171Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-25T17:52:35.078Z"
   },
   {
    "duration": 4087914,
    "start_time": "2025-03-25T17:52:54.717Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-25T19:56:43.916Z"
   },
   {
    "duration": 44316,
    "start_time": "2025-03-25T19:58:19.724Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
